-- The intent of this script is to implement some of the ideas of Kanerva
-- https://link.springer.com/article/10.1007/s12559-009-9009-8
--
-- Author: Garry Morrison
-- Created: 2023/6/21
-- Updated: 2023/6/23


|context> => |Kanerva implementation>

print |Exploring some of Kanerva's ideas using the SDB language:>
print |--------------------------------------------------------->
print | >

-- define some parameters of our hypervectors:
-- the largest bit number:
-- start with something small during testing, eg, 1000:
the |max> => |1000>
sprint["largest bit number: "] the |max>

-- the number of on bits in our hypervectors:
on |bits> => |100>
sprint["number of on bits: "] on |bits>


-- the current max "seq ket":
max |seq ket> => |0>

-- to avoid "catastrophic forgetting and interference",
-- https://en.wikipedia.org/wiki/Catastrophic_interference
-- the problem is given: A -> B, then A -> C
-- and we ask what follows A, then what do we answer? C?
-- we need some way to provide "context", one way is just define an integer
-- where that integer labels those patterns that context label:
the |time stamp> => |0>

inc-time-stamp (*) #=>
    the |time stamp> => plus[1] the |time stamp>
    |__self>

set-time-stamp (*) #=>
    the |time stamp> => |__self>
    |__self0>


-- construct some hypervectors:
-- first, a hypervector with all bits on:
the |full vector> => |0> .. the |max>

-- now learn some random hypervectors:
the |X> => pick( on |bits>) the |full vector>
the |A> => pick( on |bits>) the |full vector>
the |B> => pick( on |bits>) the |full vector>
the |C> => pick( on |bits>) the |full vector>
the |D> => pick( on |bits>) the |full vector>


-- now define our distance metric:
-- we swapped from "how-many" to "measure-currency" so we can also handle coeffs outside of {0,1}
-- d (*,*) #=> extract-value how-many XOR( |__self2>) |__self1>
d (*,*) #=> extract-value measure-currency XOR( |__self2>) |__self1>


-- a quick test:
-- we expect: |0>, |100>, |200> and commutivity respectively:
print | >
print |Testing our Hamming distance metric:>
sprint["    d(X, X): "] d( the |X>, the |X>)
sprint["    d(X, 0): "] d( the |X>, |>)
sprint["    d(X, - X): "] d( the |X>, - the |X>)
sprint["    d(X, A): "] d( the |X>, the |A>)
sprint["    d(A, X): "] d( the |A>, the |X>)


-- next, define our permutation operator:
-- NB: there may be collisions, but it shouldn't harm things too much due to the hypervector robustness
P |*> !=> (|_self> ++ random-int(|1>, the |max>) |> ) %% the |max>

-- next, the inverse permutation operator:
-- note, the inverse map is not guaranteed to be collision free because P isn't
-- NB: this operator must be invoked after "P X" has been used at least once!
create-inverse-P |*> #=>
     unlearn[inverse-P] rel-kets[inverse-P]
     find-inverse[P]

-- a quick test of our permutation operator:
print | >
print |Test the Hamming distance after applying our permutation operator P>
print |And its inverse P^-1>
print |Noting that the inverse is almost never perfect,>
print |but because of hypervector robustness this is not a problem>
sprint["    d(X, P X): "] d( the |X>, P the |X>)

-- now learn the inverse permutations, since we have just invoked "P the |X>"
create-inverse-P

-- noting that the inverse is not perfect:
sprint["    d(X, P^-1 P X): "] d( the |X>, inverse-P P the |X>)



-- next, define "op seq1 => seq2", using learn-seq and fuzzy-recall-seq:
-- where: 
-- parameter 1 is the operator ket, eg |op: foo>
-- parameter 2 is the destination sequence, eg seq2
-- the input sequence is seq1
-- this operator returns seq2, so they can be easily chained in an operator sequence
learn-seq (*,*) #=>
    max |seq ket> => plus[1] max |seq ket>
    the |ket> => |seq ket> :_ max |seq ket> :_ the |time stamp>
    seq-pattern the |ket> => |__self0>
    learn( |__self1>, the |ket>, |__self2>)
    |__self2>


-- where:
-- parameter 1 is the operator ket, eg |op: foo>
-- the input sequence is just that, the input seqence
-- the returned value is the best matching pattern for the given input sequence:
fuzzy-seq-recall (*) #=> apply(|__self1>, clean select[1,1] filter( |ops: clean extract-value>, the |time stamp>) drop-below[0.5] similar-input[seq-pattern] |__self0>)


-- now test it by applying the idea of "cleaning" the sequence:
-- the idea is you learn "clean-seq seq1 => seq1"
-- using: learn-seq( |op: clean-seq>, seq1) seq1
-- then you can apply: fuzzy-seq-recall( |op: clean-seq>) approx-seq1
-- and it will return a clean version of seq1
-- then: d( seq1, cleaned approx-seq1) should be exactly |0>

-- let's define X' to be the approximate version of X:
print | >
print |Define X' to be the approximate version of X>
print |The easiest way is to use the imperfect nature of: P^-1 P X>
the |X'> => inverse-P P the |X>

-- and now learn the identity mapping for X:
print |Learn the identity mapping: identity X maps-to X>
learn-seq( |op: identity>, the |X>) the |X>

-- and now let's clean up X':
print |Then use the stored identity mapping to clean X'>
print |Define: clean X' = identity X'>
the |clean X'> => fuzzy-seq-recall( |op: identity>) the |X'>

-- now let's compare them:
print |Now compare them:>
sprint["    d(X, X'): "] d( the |X>, the |X'>)
sprint["    d(X, clean X'): "] d( the |X>, the |clean X'>)



-- next, define "op seq1 => seq2", using learn-seq and fuzzy-recall-seq:
-- and in the process learn a label for seq1
-- where: 
-- parameter 1 is the operator ket, eg |op: foo>
-- parameter 2 is the text label for the input sequence seq1
-- parameter 3 is the destination sequence, eg seq2
-- the input sequence is seq1
-- this operator returns seq2, so they can be easily chained in an operator sequence
learn-seq (*,*,*) #=>
    max |seq ket> => plus[1] max |seq ket>
    the |ket> => |seq ket> :_ max |seq ket> :_ the |time stamp>
    seq-pattern the |ket> => |__self0>
    label the |ket> => |__self2>
    learn( |__self1>, the |ket>, |__self3>)
    |__self3>


-- given an input pattern, return its' text label:
-- we may need to tweak the drop-below threshold
-- fuzzy-recall-label (*) #=> label drop-below[0.5] similar-input[seq-pattern] |__self>
fuzzy-recall-label (*) #=> label filter( |ops: clean extract-value>, the |time stamp>) drop-below[0.5] similar-input[seq-pattern] |__self>


-- now, lets' learn a short sequence:
print | >
print |Learn the sequence: A . B . C . D>
print |Along with associated labels>
learn-seq(|op: foo>, |C>, the |D>) learn-seq(|op: foo>, |B>, the |C>) learn-seq(|op: foo>, |A>, the |B>) the |A>


-- now let's recall some labels:
print |Fuzzy recall the labels:>
sprint["    fuzzy recall label A: "] fuzzy-recall-label the |A>
sprint["    fuzzy recall label B: "] fuzzy-recall-label the |B>
sprint["    fuzzy recall label C: "] fuzzy-recall-label the |C>


-- now, let's store A -> A a couple of times:
print | >
print |Learn: identity A maps-to A, two more times>
learn-seq(|op: identity>, |A>, the |A>) the |A>
learn-seq(|op: identity>, |A>, the |A>) the |A>


-- now see what happens when we ask about A:
-- the expectation is we will get 3|A>
print |Now fuzzy recall the label for A>
print |And observe we have now stored it 3 times:>
sprint["    fuzzy recall label A: "] fuzzy-recall-label the |A>


-- let's build P for A:
print | >
print |Apply P to A once, to invoke the memoizing feature of the P operator>
the |temp> => P the |A>

-- learn the inverses:
print |Now we know P, learn the correspoding inverse: P^-1>
create-inverse-P


-- let's construct a A' hypervector using the imperfect inverse of:  inverse-P P
print |Define A' using: A' = P^-1 P A>
the |A'> => inverse-P P the |A>

-- let's check the distance between A and A':
-- we expect a small but non-zero number:
print |Check the distance between A and A'>
sprint["    d(A, A'): "] d( the |A>, the |A'>)

-- now, let's fuzzy recall the label of A':
-- we expect the coeff to be less than 3:
print | >
print |Now ask it to fuzzy recall the label for A'>
print |Observing, if A' == A it should be: 3 A>
print |But because A' != A, it is a little lower than that>
sprint["    fuzzy recall label A': "] fuzzy-recall-label the |A'>


-- next, let's learn an inhibition:
-- let's say A' inhibits A
print | >
print |Now make use of the fact we can learn inhibition too>
print |Learn the mapping: foo A' maps-to -A>
learn-seq(|op: foo>, -|A>, - the |A>) the |A'>


-- now see what we get when we fuzzy recall label of A:
-- we expect the coeff to be just above 2:
print |Now see what we get when we fuzzy recall the label for the hypervector A>
print |Seeing that it is now a little lower than the original: 3 A>
sprint["    fuzzy recall label A: "] fuzzy-recall-label the |A>

-- now, change the time stamp, and we should not recall anything:
print | >
print |To avoid "catastrophic interference" each stored pattern has an associated context>
print |See: https://en.wikipedia.org/wiki/Catastrophic_interference>
print |For now we use an integer to represent a given context, but any string will work>
print |So if we change to a new "context" and then ask to fuzzy recall the label for A, we get the empty ket:>
the |time stamp> => |1>
sprint["    fuzzy recall label A: "] fuzzy-recall-label the |A>

print | >
print |If we change it back to a known context, we get the expected result:>
the |time stamp> => |0>
sprint["    fuzzy recall label A: "] fuzzy-recall-label the |A>



-- now a couple of notes:
-- the multiplication: D * C * B * A
-- is implemented as this operator sequence:
-- XOR(D) XOR(C) XOR(B) A

-- we learn the sequence: A -> B -> C -> D
-- using this operator sequence:
-- learn-seq( |op: foo>, D) learn-seq( |op: foo>, C) learn-seq( |op: foo>, B) A


